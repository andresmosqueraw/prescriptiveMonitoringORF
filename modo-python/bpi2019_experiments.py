# -*- coding: utf-8 -*-
"""bpi2019_experiments.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1t-yjDIUJoTOVSGHGUsU9Tpmsm4cxdnB1
"""

import sys
import os

import pandas as pd
import numpy as np
from numpy import savetxt
from tqdm import tqdm, tqdm_notebook
from sklearn.preprocessing import StandardScaler
pd.set_option('display.max_columns', None)
import itertools

# Ensure we use the local EconML package in this repo instead of (or before) any pip-installed version
EconML_repo_path = os.path.abspath(
    os.path.join(
        os.path.dirname(__file__),
        os.pardir,  # go up from modo-python
        os.pardir,  # go up into prescriptive-process-monitoring-cost-aware-cycle-time-reduction
        os.pardir,  # up into prescriptive-process-monitoring
        "EconML"
    )
)
if EconML_repo_path not in sys.path:
    sys.path.insert(0, EconML_repo_path)

import econml
import warnings
# warnings.filterwarnings('ignore')

# Main imports adapted to new EconML layout
from econml.orf import DMLOrthoForest, DROrthoForest
from econml.sklearn_extensions.linear_model import WeightedLassoCVWrapper, WeightedLasso, WeightedLassoCV

from econml.cate_interpreter import SingleTreeCateInterpreter, SingleTreePolicyInterpreter
import graphviz

# Helper imports
import numpy as np
from itertools import product
from sklearn.linear_model import Lasso, LassoCV, LogisticRegression, LogisticRegressionCV
import matplotlib.pyplot as plt

# %matplotlib inline

# A few more imports
import os
import pandas as pd
import urllib.request
from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split

from sklearn.linear_model import Lasso, LassoCV, LinearRegression, Ridge, ElasticNet
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_absolute_error

case_id_col = "Case ID"
activity_col = "Activity"
resource_col = "org:resource"
timestamp_col = "time:timestamp"

treatment = 'treatment'
outcome = 'duration'

dynamic_cat_cols = ['Activity', 'org:resource']
static_cat_cols = ['(case)_Item_Type', '(case)_Spend_area_text', '(case)_Sub_spend_area_text', '(case)_Vendor',
                   '(case)_GR-Based_Inv__Verif_', '(case)_Spend_classification_text', '(case)_Item_Category', '(case)_Company',
                   '(case)_Name', '(case)_Document_Type']
dynamic_num_cols = ['Cumulative_net_worth_(EUR)', 'open_cases', 'month', 'weekday', 'hour', 'timesincelastevent', 'timesincecasestart']
static_num_cols = ['timesincefirstcase', '(case)_Item', 'duration', 'treatment']

cat_cols = dynamic_cat_cols + static_cat_cols
num_cols = dynamic_num_cols + static_num_cols

tqdm.pandas()

df2 = pd.read_csv('data_bpic19_readyToUse.csv')
df2['treatment'] = df2[treatment].replace({0:1, 1:0})

# Define some parameters
N_trees = [200]
Min_leaf_size = [10]
Max_depth = [10]
Subsample_ratio = [0.7]
Lambda_reg= [0.01]

# para prueba rapida
# N_trees = [1]
# Min_leaf_size = [200]
# Max_depth = [1]
# Subsample_ratio = [0.1]
# Lambda_reg= [1.0]

# preparing the data
train, valid = train_test_split(df2, test_size=0.2, shuffle=False)
train, test = train_test_split(train, test_size=0.2, shuffle=False)
features = train.drop([outcome, treatment], axis=1)
features_test = test.drop([outcome, treatment], axis=1)


cat_confound_cols = ['(case)_Item_Type',  '(case)_Spend_area_text', '(case)_Sub_spend_area_text',
                     '(case)_Vendor', '(case)_GR-Based_Inv__Verif_', '(case)_Spend_classification_text',
                     '(case)_Item_Category','(case)_Name', '(case)_Company', '(case)_Document_Type', '(case)_Item']
num_confound_cols = features.columns.difference(cat_confound_cols)


cat_hetero_cols = ['(case)_Item_Type', '(case)_Spend_area_text', '(case)_Sub_spend_area_text',
                   '(case)_Vendor', '(case)_GR-Based_Inv__Verif_', '(case)_Spend_classification_text',
                   '(case)_Item_Category', '(case)_Name', '(case)_Company', '(case)_Document_Type', '(case)_Item']
num_hetero_cols = features.columns.difference(cat_hetero_cols)
#num_hetero_cols = ['Cumulative_net_worth_(EUR)']

Y = train[outcome].to_numpy()
T = train[treatment].to_numpy()
scaler = StandardScaler()
W1 = scaler.fit_transform(features[[c for c in num_confound_cols]].to_numpy())
W2 = pd.get_dummies(features[cat_confound_cols]).to_numpy()
W = np.concatenate([W1, W2], axis=1)
X1 = scaler.fit_transform(features[[c for c in num_hetero_cols]].to_numpy())
X2 = pd.get_dummies(features[cat_hetero_cols]).to_numpy()
X = np.concatenate([X1, X2], axis=1)

X1_test = scaler.fit_transform(features_test[[c for c in num_hetero_cols]].to_numpy())
X2_test = pd.get_dummies(features_test[cat_hetero_cols]).to_numpy()
X_test = np.concatenate([X1_test, X2_test], axis=1)

tmp = pd.DataFrame(X)
tmp2 = pd.DataFrame(X_test)

# Get missing columns in the training test
missing_cols = set( tmp.columns ) - set( tmp2.columns )
# Add a missing column in test set with default value equal to 0
for c in missing_cols:
    tmp2[c] = 0
# Ensure the order of column in the test set is in the same order than in train set
tmp2 = tmp2[tmp.columns]

X_test = tmp2.to_numpy()

# curve for the test set
for i in itertools.product(N_trees, Min_leaf_size, Max_depth, Subsample_ratio, Lambda_reg):
    print(i)
    n_trees = i[0]
    min_leaf_size = i[1]
    max_depth = i[2]
    subsample_ratio = i[3]
    lambda_reg = i[4]
    est = DMLOrthoForest(
        n_trees=n_trees, min_leaf_size=min_leaf_size, max_depth=max_depth,
        subsample_ratio=subsample_ratio, discrete_treatment=True,
        model_T=LogisticRegression(C=1/(X.shape[0]*lambda_reg), penalty='l1', solver='saga'),
        model_Y=Lasso(alpha=lambda_reg),
        model_T_final=LogisticRegression(C=1/(X.shape[0]*lambda_reg), penalty='l1', solver='saga'),
        model_Y_final=WeightedLasso(alpha=lambda_reg),
        random_state=200
       )

    # Nueva firma de DMLOrthoForest en econml requiere X y W como argumentos con nombre
    ortho_model = est.fit(Y, T, X=X, W=W)
    batches = np.array_split(X_test, X_test.shape[0] / 100)
    treatment_effects = est.const_marginal_effect(batches[0])
    ii = 0
    for batch in batches[1:]:
#         print(ii)
        estimates = est.const_marginal_effect(batch)
        treatment_effects = np.append(treatment_effects, estimates)
        ii += 1
    df_results = test
    df_results['Treatment Effects'] = treatment_effects

#     Calculate default (90%) confidence intervals for the default treatment points T0=0 and T1=1
#     te_lower, te_upper = est.effect_interval(batches[0])
#     ii = 0
#     for batch in batches[1:]:
#         print(ii)
#         lower, upper = est.effect_interval(batch)
#         te_lower = np.append(te_lower, lower)
#         te_upper = np.append(te_upper, upper)
#         ii += 1

#     df_results['te_lower'] = te_lower
#     df_results['te_upper'] = te_upper
#     df_results['Interval Length'] = df_results['te_upper'] - df_results['te_lower']

    net_value = [0]
    net_value2 = [0]
    net_value3 = [0]

    percentages = [10,20,30,40,50,60,70,80,90,100]

    for n in percentages:
        num = int(len(df_results)*(n/100))
        top_n = df_results.nsmallest(num,'Treatment Effects')
        n_treated = top_n[top_n['treatment']==1].shape[0]
        n_control = top_n[top_n['treatment']==0].shape[0]
        scale_factor = n_treated/n_control

        treated = top_n[top_n['treatment']==1]['duration'].sum()
        control = top_n[top_n['treatment']==0]['duration'].sum()

        reduction = (scale_factor*control) - treated
        net_value.append(reduction)

#     for n in percentages:
#         num = int(len(df_results)*(n/100))
#         top_n = df_results.nsmallest(num,'te_lower')
#         n_treated = top_n[top_n['treatment']==1].shape[0]
#         n_control = top_n[top_n['treatment']==0].shape[0]
#         scale_factor = n_treated/n_control

#         treated = top_n[top_n['treatment']==1]['duration'].sum()
#         control = top_n[top_n['treatment']==0]['duration'].sum()

#         reduction = (scale_factor*control) - treated
#         net_value2.append(reduction)

#     for n in percentages:
#         num = int(len(df_results)*(n/100))
#         top_n = df_results.nsmallest(num,'te_upper')
#         n_treated = top_n[top_n['treatment']==1].shape[0]
#         n_control = top_n[top_n['treatment']==0].shape[0]
#         scale_factor = n_treated/n_control

#         treated = top_n[top_n['treatment']==1]['duration'].sum()
#         control = top_n[top_n['treatment']==0]['duration'].sum()

#         reduction = (scale_factor*control) - treated
#         net_value3.append(reduction)

    plt.plot([0]+percentages, net_value, label="Treatment Effect", marker="o")
#     plt.plot([0]+percentages, net_value2, label="TE Lower bound", marker="o", color='Green')
#     plt.plot([0]+percentages, net_value3, label="TE Upper bound", marker="o", color='Red')
    plt.plot([0,percentages[9]], [0,net_value[10]], label="Random",  marker="o", color='Black',
             linestyle='dashed')
    plt.xlabel('Proportion of cases targeted')
    plt.ylabel('Expected incremental reduction')
    plt.legend(loc='best')
    plt.title(i)

    plt.savefig('Results/Qini_curve_BPIC19_%s.png'%str(i), format='png', dpi=300)

df_results.to_csv('Results/dataframe_with_results_BPIC19', index=False)

# Data prep for running baseline
train = train[train[treatment]==0]
features = train.drop([outcome, treatment, case_id_col], axis=1)
features_test = test.drop([outcome, treatment], axis=1)

cat_confound_cols = ['(case)_Item_Type',  '(case)_Spend_area_text', '(case)_Sub_spend_area_text',
                     '(case)_Vendor', '(case)_GR-Based_Inv__Verif_', '(case)_Spend_classification_text',
                     '(case)_Item_Category','(case)_Name', '(case)_Company', '(case)_Document_Type', '(case)_Item']
num_confound_cols = features.columns.difference(cat_confound_cols)


cat_hetero_cols = ['(case)_Item_Type', '(case)_Spend_area_text', '(case)_Sub_spend_area_text',
                   '(case)_Vendor', '(case)_GR-Based_Inv__Verif_', '(case)_Spend_classification_text',
                   '(case)_Item_Category', '(case)_Name', '(case)_Company', '(case)_Document_Type', '(case)_Item']
num_hetero_cols = features.columns.difference(cat_hetero_cols)
#num_hetero_cols = ['Cumulative_net_worth_(EUR)']

Y = train[outcome].to_numpy()
T = train[treatment].to_numpy()
scaler = StandardScaler()

X1 = scaler.fit_transform(features[[c for c in num_hetero_cols]].to_numpy())
X2 = pd.get_dummies(features[cat_hetero_cols]).to_numpy()
X = np.concatenate([X1, X2], axis=1)

X1_test = scaler.fit_transform(features_test[[c for c in num_hetero_cols]].to_numpy())
X2_test = pd.get_dummies(features_test[cat_hetero_cols]).to_numpy()
X_test = np.concatenate([X1_test, X2_test], axis=1)

tmp = pd.DataFrame(X)
tmp2 = pd.DataFrame(X_test)

# Get missing columns in the training test
missing_cols = set( tmp.columns ) - set( tmp2.columns )
# Add a missing column in test set with default value equal to 0
for c in missing_cols:
    tmp2[c] = 0
# Ensure the order of column in the test set is in the same order than in train set
tmp2 = tmp2[tmp.columns]

X_test = tmp2.to_numpy()

percentages = [10,20,30,40,50,60,70,80,90,100]

pred = Lasso()
pred.fit(X,Y)

pred2 = RandomForestRegressor()
pred2.fit(X,Y)

yhat_test = pred.predict(X_test)
print('MAE of test:', mean_absolute_error(test[outcome], yhat_test))
df_results['predictions_lasso'] = yhat_test

yhat_test2 = pred2.predict(X_test)
print('MAE of test:', mean_absolute_error(test[outcome], yhat_test2))
df_results['predictions_RF'] = yhat_test2

net_value = [0]
net_value2 = [0]
net_value3 = [0]
for n in percentages:
    num = int(len(df_results)*(n/100))
    top_n = df_results.nsmallest(num,'Treatment Effects')
    n_treated = top_n[top_n['treatment']==1].shape[0]
    n_control = top_n[top_n['treatment']==0].shape[0]
    scale_factor = n_treated/n_control

    treated = top_n[top_n['treatment']==1]['duration'].sum()
    control = top_n[top_n['treatment']==0]['duration'].sum()

    reduction = (scale_factor*control) - treated
    net_value.append(reduction)

for n in percentages:
    num = int(len(df_results)*(n/100))
    top_n = df_results.nsmallest(num,'predictions_lasso')
    n_treated = top_n[top_n['treatment']==1].shape[0]
    n_control = top_n[top_n['treatment']==0].shape[0]
    scale_factor = n_treated/n_control

    treated = top_n[top_n['treatment']==1]['duration'].sum()
    control = top_n[top_n['treatment']==0]['duration'].sum()

    reduction = (scale_factor*control) - treated
    net_value2.append(reduction)

for n in percentages:
    num = int(len(df_results)*(n/100))
    top_n = df_results.nsmallest(num,'predictions_RF')
    n_treated = top_n[top_n['treatment']==1].shape[0]
    n_control = top_n[top_n['treatment']==0].shape[0]
    scale_factor = n_treated/n_control

    treated = top_n[top_n['treatment']==1]['duration'].sum()
    control = top_n[top_n['treatment']==0]['duration'].sum()

    reduction = (scale_factor*control) - treated
    net_value3.append(reduction)
#     net_value.append(reduction)

#normed = norm = [(float(i)-min(net_value))/(max(net_value)-min(net_value)) for i in net_value]


# plt.figure(figsize=(10, 4))
# plt.subplot(1, 2, 1)
plt.plot([0]+percentages, net_value, label="Orthogonal Random Forest", marker="o")
plt.plot([0]+percentages, net_value3, label="RandomForestRegressor", marker="o", color='Red')
plt.plot([0]+percentages, net_value2, label="Lasso", marker="o", color='Green')
plt.plot([0,percentages[9]], [0,net_value[10]], label="Random Policy",  marker="o", color='Black',
         linestyle='dashed')
plt.xlabel('Proportion of Cases Targeted')
plt.ylabel('Expected Incremental Reduction in Duration')
plt.legend(loc='best')
plt.title('Qini Curve')

# Asegurar que la carpeta Results existe antes de guardar
os.makedirs('Results', exist_ok=True)

plt.savefig('Results/Qini_curve_BPIC19_withBaseline.png', format='png', dpi=300)
plt.close()

# net value curves
value = [1]
cost = [0.3,0.5,1,2,3]

percentages = [10,20,30,40,50,60,70,80,90,100]

plt.figure()
for i in itertools.product(value, cost):
    v = i[0]
    c = i[1]
    net_value = [0]
    for n in percentages:
        num = int(len(df_results)*(n/100))
        top_n = df_results.nsmallest(num,'Treatment Effects')
        n_treated = top_n[top_n['treatment']==1].shape[0]
        n_control = top_n[top_n['treatment']==0].shape[0]
        scale_factor = n_treated/n_control

        treated = top_n[top_n['treatment']==1]['duration'].sum()
        control = top_n[top_n['treatment']==0]['duration'].sum()

        reduction = (scale_factor*control) - treated
        net_val = (reduction*v) - (3*n_treated*c)
#         print(net_val)
        net_value.append(net_val)
    #     net_value.append(reduction)

    #normed = norm = [(float(i)-min(net_value))/(max(net_value)-min(net_value)) for i in net_value]


    # plt.figure(figsize=(10, 4))
    # plt.subplot(1, 2, 1)
    plt.plot([0]+percentages, net_value, label="v/c=%s"%str(round(v/c,1)), marker="o")
    #     plt.plot([0]+percentages, net_value2, label="TE Lower bound", marker="o", color='Green')
    #     plt.plot([0]+percentages, net_value3, label="TE Upper bound", marker="o", color='Red')
#     plt.plot([0,percentages[9]], [0,net_value[10]], label="Random Policy",  marker="o", color='Black',
#              linestyle='dashed')
plt.xlabel('Proportion of Cases Targeted')
plt.ylabel('Expected Net Value')
plt.legend(loc='best')
plt.title('Net-value Curve')

plt.savefig('Results/NetVal_curve_BPIC19.png', format='png', dpi=300)
plt.close()
